{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import datetime as dt\n",
    "from ipywidgets import interact\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import tqdm\n",
    "import vectorbtpro as vbt\n",
    "\n",
    "import legitindicators as li\n",
    "import pandas_ta as pta\n",
    "\n",
    "from lib import bitget_loader, utils, indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = 'GALAUSDT'\n",
    "freq = '4h'\n",
    "\n",
    "is_start = dt.date(2021,1,1)\n",
    "is_end = dt.date(2022,12,31)\n",
    "\n",
    "os_start = dt.date(2023,1,1)\n",
    "os_end = dt.date(2024,10,10)\n",
    "\n",
    "df = pd.read_parquet(f\"../data/candles/{symbol}.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.resample(freq).agg({'open':'first', 'high':'max', 'low':'min', 'close':'last', 'volume':'sum', 'quoteVolume':'sum', 'nTrades':'sum', 'upVolume':'sum', 'upQuoteVolume':'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume'] = df['volume'].replace({0:np.nan})\n",
    "df['quoteVolume'] = df['quoteVolume'].replace({0:np.nan})\n",
    "df['nTrades'] = df['nTrades'].replace({0:np.nan})\n",
    "df['upVolume'] = df['upVolume'].replace({0:np.nan})\n",
    "df['upQuoteVolume'] = df['upQuoteVolume'].replace({0:np.nan})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y_return'] = np.where(df['close']-df['open']>0, 1, np.where(df['close']-df['open']<0, -1, np.nan))\n",
    "#df['y_return'] = df['close'].diff(5)>0\n",
    "df['y_return'] = df['y_return'].shift(-1)\n",
    "df = df.iloc[:-1].copy() # last row has no target, so drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['tma1'] = df['close'].rolling(12).mean().rolling(12).mean().shift(-11)\n",
    "# df['tma2'] = df['close'].rolling(24).mean().rolling(24).mean().shift(-23)\n",
    "# df['tma3'] = df['close'].rolling(48).mean().rolling(48).mean().shift(-47)\n",
    "\n",
    "# df['y_return'] = np.where((df['tma1'].diff()>0) & (df['tma2'].diff()>0) & (df['tma3'].diff()>0), 1, np.where((df['tma1'].diff()<0) & (df['tma2'].diff()<0) & (df['tma3'].diff()<0), -1, np.nan))\n",
    "# df['y_return'] = df['y_return'].shift(-1)\n",
    "# df = df.iloc[:-1].copy() # last row has no target, so drop it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_return_zs'] = pta.zscore(df['close'].pct_change(), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [7, 25, 99]:\n",
    "    df[f'x_momnom_{l}'] = li.momentum_normalized(df['close'], l)\n",
    "    df[f'sma_{l}'] = df['close'].rolling(l).mean()\n",
    "    # df[f'x_sma_{l}_roc'] = df[f'sma_{l}'].pct_change()\n",
    "    # df[f'x_sma_{l}_distance'] = (df['close']-df[f'sma_{l}'])/df[f'sma_{l}']\n",
    "\n",
    "for p in itertools.combinations([7, 25, 99], 2):\n",
    "    df[f'x_sma_{p[0]}_{p[1]}_distance'] = (df[f'sma_{p[0]}']-df[f'sma_{p[1]}'])/df[f'sma_{p[1]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in [7, 25, 99]:\n",
    "    df[[f'x_adx_{l}', f'x_dmp_{l}', f'x_dmn_{l}']] = pta.adx(df['high'], df['low'], df['close'], l)\n",
    "    df[f'x_adx_{l}'] = li.szladx(df[['high', 'low', 'close']].values, l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logvolume'] = np.log(df['volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12, 4))\n",
    "df['volume'][df['volume'].rank(pct=True)<0.9].hist(ax=ax[0])\n",
    "df['logvolume'].hist(ax=ax[1])\n",
    "ax[0].set_title(\"Distribution of Volume\")\n",
    "ax[1].set_title(\"Distribution of log(Volume)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_logvolume_zs'] = pta.zscore(df['logvolume'], 200)\n",
    "df['x_logvolume_zs_ma'] = df['x_logvolume_zs'].rolling(20).mean()\n",
    "df['x_relative_volume_zs'] = df['logvolume'].groupby(df.index.time).apply(lambda d: pta.zscore(d, 40)).droplevel(0).sort_index()\n",
    "df['x_relative_volume_zs_ma'] = df['x_relative_volume_zs'].rolling(20).mean()\n",
    "df['x_volume_corr'] = df['volume'].rolling(20).corr(df['close'].pct_change().abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['logticks'] = np.log(df['nTrades'])\n",
    "df['x_logticks_zs'] = pta.zscore(df['logticks'], 200)\n",
    "df['x_logticks_zs_ma'] = df['x_logticks_zs'].rolling(20).mean()\n",
    "df['x_relative_ticks_zs'] = df['logticks'].groupby(df.index.time).apply(lambda d: pta.zscore(d, 40)).droplevel(0).sort_index()\n",
    "df['x_relative_ticks_zs_ma'] = df['x_relative_ticks_zs'].rolling(20).mean()\n",
    "df['x_ticks_corr'] = df['nTrades'].rolling(20).corr(df['close'].pct_change().abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tr'] = pta.true_range(df['high'], df['low'], df['close'])\n",
    "df['logtr'] = np.log(df['tr'])\n",
    "\n",
    "# df['x_tr_zs'] = pta.zscore(df['logtr'], 20)\n",
    "# df['x_tr_zs_ma'] = df['x_tr_zs'].rolling(20).mean()\n",
    "# df['x_relative_tr_zs'] = df['logtr'].groupby(df.index.time).apply(lambda d: pta.zscore(d, 20)).droplevel(0).sort_index()\n",
    "# df['x_relative_tr_zs_ma'] = df['x_relative_tr_zs'].rolling(20).mean()\n",
    "df['x_range_zs'] = pta.zscore(np.log((df['high']-df['low'])/df['open']), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['natr'] = df['tr'].ewm(20).mean()/df['close']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['volume_delta'] = 2*df['upVolume'] - df['volume']\n",
    "for l in [1, 4, 12]:\n",
    "    df[f'x_volume_delta_{l}_zs'] = pta.zscore(df['volume_delta'].rolling(l).sum(), 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x_dvolm'] = li.damiani_volatmeter(df[['open', 'high', 'low', 'close']].values, 13, 20, 40, 100, 1.4)\n",
    "df['x_quote_vol_per_trade'] = pta.zscore(np.log(df['volume']/df['nTrades']), 200)\n",
    "df['x_vol_per_trade'] = pta.zscore(np.log(df['quoteVolume']/df['nTrades']), 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['x_ebsw'] = li.ebsw(df['close'], 40, 10)\n",
    "# df['x_tf'] = indicators.TrendFlex(df['close'], 30)\n",
    "# df['x_rf'] = indicators.Reflex(df['close'], 30)\n",
    "# df['x_voss'] = li.voss(df['close'].values, 20, 3, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for l in [9, 25, 99]:\n",
    "#     df[f'x_ker_{l}'] = li.kaufman_er(df['close'], l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(make_subplots(rows=3, cols=1, shared_xaxes=True, row_heights=[0.6, 0.2, 0.2]))\n",
    "fig.add_trace(go.Candlestick(), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(), row=3, col=1)\n",
    "fig.update_layout(height=600, margin=dict(l=20,r=20,b=20,t=20), xaxis=dict(rangeslider=dict(visible=False)))\n",
    "\n",
    "@interact(date=np.unique(df.index.date), col=df.columns, col2=df.columns)\n",
    "def update(date, col, col2):\n",
    "   with fig.batch_update():\n",
    "      _sdf = df.loc[str(date)]\n",
    "      fig.data[0].x, fig.data[0].open, fig.data[0].high = _sdf.index, _sdf['open'], _sdf['high']\n",
    "      fig.data[0].low, fig.data[0].close = _sdf['low'], _sdf['close']\n",
    "      fig.data[1].x, fig.data[1].y = _sdf.index, _sdf[col]\n",
    "      fig.data[2].x, fig.data[2].y = _sdf.index, _sdf[col2]\n",
    "      fig.update_layout()\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import ClassificationExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "ymask = ~pd.isna(df['y_return'])\n",
    "\n",
    "x_train = df[ymask].loc[:is_end][utils.get_prefixed_cols(df, 'x_')].replace({np.inf:np.nan, -np.inf:np.nan})\n",
    "y_train = df[ymask].loc[:is_end]['y_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ClassificationExperiment()\n",
    "exp.setup(\n",
    "    data=x_train, target=y_train,\n",
    "    train_size=0.7,\n",
    "    data_split_shuffle=False,\n",
    "    data_split_stratify=False,\n",
    "    numeric_imputation='mean',\n",
    "    # remove_multicollinearity=True,\n",
    "    # multicollinearity_threshold=0.8,\n",
    "    normalize=False,\n",
    "    pca=False,\n",
    "    # feature_selection=True,\n",
    "    # n_features_to_select=0.5,\n",
    "    remove_outliers=False,\n",
    "    fold_strategy='kfold',\n",
    "    fold=5,\n",
    "    fold_shuffle=False,\n",
    "    # keep_features = x_cols,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.X_transformed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = exp.compare_models(n_select=3, cross_validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = exp.create_model('gbc', cross_validation=False)\n",
    "# best = exp.create_model('lr', cross_validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp.tune_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.plot_model(best, 'threshold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.plot_model(best, plot='feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = permutation_importance(best, exp.X_test_transformed, exp.y_test, n_repeats=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in r.importances_mean.argsort()[::-1]:\n",
    "#     if r.importances_mean[i] - 1 * r.importances_std[i] > 0:\n",
    "#         print(f\"{best.feature_name_[i]:<8}\"\n",
    "#               f\" {r.importances_mean[i]:.3f}\"\n",
    "#               f\" +/- {r.importances_std[i]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Holdout Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backtest in Modelling Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = df.loc[exp.test.index]\n",
    "bdf['prediction_label'] = exp.predict_model(best)['prediction_label']\n",
    "bdf['prediction_score'] = exp.predict_model(best)['prediction_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = bdf['prediction_label'] == 1\n",
    "le &= bdf['prediction_score'] > 0.65\n",
    "\n",
    "se = bdf['prediction_label'] == -1\n",
    "se &= bdf['prediction_score'] > 0.65\n",
    "\n",
    "le = utils.crossover(le, 0.5)\n",
    "se = utils.crossover(se, 0.5)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    bdf['close'], open=bdf['open'], high=bdf['high'], low=bdf['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=3,\n",
    "    time_delta_format=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal Half-Life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    bdf['close'], open=bdf['open'], high=bdf['high'], low=bdf['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=vbt.Param(np.arange(2, 20)),\n",
    "    time_delta_format=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "pf.trades.win_rate.plot(ax=ax[0], title='Win Rate')\n",
    "pf.trades.profit_factor.plot(ax=ax[1], title='Profit Factor')\n",
    "ax[0].axhline(0.5, alpha=0.5)\n",
    "ax[1].axhline(1, alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_td_stop = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPSL Opt, Pct Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsl_mults = np.arange(0.005, 0.2, 0.005)\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    bdf['close'], open=bdf['open'], high=bdf['high'], low=bdf['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=best_td_stop,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=vbt.Param(tpsl_mults),\n",
    "    tp_stop=vbt.Param(tpsl_mults),\n",
    "    slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_result = pf.trades.get_profit_factor().unstack()\n",
    "# stat_result = pf.trades.win_rate.unstack()\n",
    "stat_result = stat_result.sort_index().sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(stat_result, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPSL Opt, ATR Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsl_mults = np.arange(0.5, 8, 0.5)\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    bdf['close'], open=bdf['open'], high=bdf['high'], low=bdf['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=best_td_stop,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=vbt.Param([x*bdf['natr'] for x in tpsl_mults]),\n",
    "    tp_stop=vbt.Param([x*bdf['natr'] for x in tpsl_mults]),\n",
    "    slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_result = pf.trades.get_profit_factor().unstack()\n",
    "stat_result.index = stat_result.index.str[7:].astype(int)\n",
    "stat_result.columns = stat_result.columns.str[7:].astype(int)\n",
    "stat_result = stat_result.sort_index().sort_index(axis=1)\n",
    "stat_result.index = tpsl_mults\n",
    "stat_result.columns = tpsl_mults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(stat_result, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sl = 2.5\n",
    "best_tp = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = vbt.Portfolio.from_signals(\n",
    "    bdf['close'], open=bdf['open'], high=bdf['high'], low=bdf['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=best_td_stop,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=best_sl*bdf['natr'],\n",
    "    tp_stop=best_tp*bdf['natr'],\n",
    "    #sl_stop=0.05,\n",
    "    #tp_stop=0.1,\n",
    "    slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.value.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtest OOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = exp.finalize_model(best)\n",
    "# final_model = exp.finalize_model(best, model_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_df = df.sort_index().loc[os_start:]\n",
    "os_df['prediction_label'] = final_model.predict(os_df[utils.get_prefixed_cols(os_df, 'x_')]).values\n",
    "os_df['prediction_score'] = final_model.predict_proba(os_df[utils.get_prefixed_cols(os_df, 'x_')])[:,1]\n",
    "os_df['prediction_score'] = np.where(os_df['prediction_label']==1, os_df['prediction_score'], 1-os_df['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = os_df['prediction_label'] == 1\n",
    "le &= os_df['prediction_score'] > 0.65\n",
    "se = os_df['prediction_label'] == -1\n",
    "se &= os_df['prediction_score'] > 0.65\n",
    "\n",
    "le = utils.crossover(le, 0.5)\n",
    "se = utils.crossover(se, 0.5)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    os_df['close'], open=os_df['open'], high=os_df['high'], low=os_df['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=best_td_stop,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=best_sl*os_df['natr'],\n",
    "    tp_stop=best_tp*os_df['natr'],\n",
    "    slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pf.trades.records\n",
    "records['dt'] = os_df.index[records['entry_idx']]\n",
    "records['exit_dt'] = os_df.index[records['exit_idx']]\n",
    "records['sl'] = best_sl*os_df['natr'].iloc[records['entry_idx']].values\n",
    "records['realized_r'] = records['return']/records['sl']\n",
    "records = records.set_index('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['realized_r'].cumsum().vbt.plot().show(renderer='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling Weekly Train-Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weeknum'] = (df.index.weekday.diff() < 0).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = 26\n",
    "\n",
    "df['prediction_label'] = np.nan\n",
    "df['prediction_score'] = np.nan\n",
    "\n",
    "for week in tqdm.tqdm(range(training_window+2, df['weeknum'].max()+1)):\n",
    "    train_df = df[df['weeknum'].between(week-training_window, week-1)]\n",
    "    pred_df = df[df['weeknum']==week]\n",
    "    \n",
    "    x_train = train_df[utils.get_prefixed_cols(train_df, 'x_')]\n",
    "    ymask = ~train_df['y_return'].isna()\n",
    "    xmask = ~x_train.isna().any(axis=1)\n",
    "    \n",
    "    final_model.fit(x_train[ymask&xmask], train_df['y_return'][ymask&xmask])\n",
    "\n",
    "    df['prediction_label'].update(pd.Series(final_model.predict(pred_df[utils.get_prefixed_cols(pred_df, 'x_')]).values, pred_df.index))\n",
    "    df['prediction_score'].update(pd.Series(final_model.predict_proba(pred_df[utils.get_prefixed_cols(pred_df, 'x_')])[:,1], pred_df.index))\n",
    "\n",
    "df['prediction_score'] = np.where(df['prediction_label']==1, df['prediction_score'], 1-df['prediction_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = df['prediction_label'] == 1\n",
    "le &= df['prediction_score'] > 0.75\n",
    "se = df['prediction_label'] == -1\n",
    "se &= df['prediction_score'] > 0.75\n",
    "\n",
    "le = utils.crossover(le, 0.5)\n",
    "se = utils.crossover(se, 0.5)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    df['close'], open=df['open'], high=df['high'], low=df['low'],\n",
    "    entries=le, short_entries=se,\n",
    "    freq=freq,\n",
    "    td_stop=best_td_stop,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=best_sl*df['natr'],\n",
    "    tp_stop=best_tp*df['natr'],\n",
    "    slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pf.trades.records\n",
    "records['dt'] = df.index[records['entry_idx']]\n",
    "records['exit_dt'] = df.index[records['exit_idx']]\n",
    "records['sl'] = best_sl*df['natr'].iloc[records['entry_idx']].values\n",
    "records['realized_r'] = records['return']/records['sl']\n",
    "records = records.set_index('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['realized_r'].cumsum().plot()\n",
    "records[records['direction']==0]['realized_r'].cumsum().plot()\n",
    "records[records['direction']==1]['realized_r'].cumsum().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTF Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(indicators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_parquet(f\"../data/candles/{symbol}.pq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ssmooth'] = indicators.SuperSmoother(df1['close'], 10)\n",
    "df1['decycler'] = indicators.Decycler(df1['close'], 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ma1'] = indicators.SuperSmoother(df1['close'], 9)\n",
    "df1['ma2'] = indicators.SuperSmoother(df1['close'], 25)\n",
    "df1['ma3'] = indicators.SuperSmoother(df1['close'], 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['prediction_label'] = df['prediction_label'].shift(freq='14min')\n",
    "df1['prediction_score'] = df['prediction_score'].shift(freq='14min')\n",
    "df1['prediction_label'] = df1['prediction_label'].ffill()\n",
    "df1['prediction_score'] = df1['prediction_score'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "espf_length = 20\n",
    "espf_bw = 1\n",
    "df1['espf'] = indicators.SuperPassband(df1['close'], espf_length-espf_bw, espf_length+espf_bw)\n",
    "df1['rms'] = indicators.RMS(df1['espf'], espf_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = df1['ma1']>df1['ma2']\n",
    "# # le &= df1['ma2']>df1['ma3']\n",
    "\n",
    "# se = df1['ma1']<df1['ma2']\n",
    "# # se &= df1['ma2']<df1['ma3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['tf'] = indicators.TrendFlex(df1['close'], 30)\n",
    "df1['rf'] = indicators.Reflex(df1['close'], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = utils.crossover(df1['rf'], df1['tf'])\n",
    "# se = utils.crossover(df1['tf'], df1['rf'])\n",
    "\n",
    "le = df1['rf'] >df1['tf']\n",
    "se = df1['tf'] <df1['rf']\n",
    "\n",
    "lx = utils.crossover(df1['tf'], df1['rf'])\n",
    "sx = utils.crossover(df1['rf'], df1['tf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_mult = 1\n",
    "le = utils.crossover(df1['espf'], rms_mult*df1['rms'])\n",
    "se = utils.crossover(-rms_mult*df1['rms'], df1['espf'])\n",
    "sx = utils.crossover(df1['espf'], df1['rms'])\n",
    "lx = utils.crossover(df1['rms'], df1['espf'])\n",
    "\n",
    "# le = utils.crossover(df1['ssmooth'], df1['decycler'])\n",
    "# se = utils.crossover(df1['decycler'], df1['ssmooth'])\n",
    "# sx = utils.crossover(df1['ssmooth'], df1['decycler'])\n",
    "# lx = utils.crossover(df1['decycler'], df1['ssmooth'])\n",
    "\n",
    "# le = df1['rf'] >df1['tf']\n",
    "# se = df1['tf'] <df1['rf']\n",
    "\n",
    "# lx = utils.crossover(df1['tf'], df1['rf'])\n",
    "# sx = utils.crossover(df1['rf'], df1['tf'])\n",
    "\n",
    "le &= df1['prediction_label'] == 1\n",
    "le &= df1['prediction_score'] > 0.7\n",
    "se &= df1['prediction_label'] == -1\n",
    "se &= df1['prediction_score'] > 0.7\n",
    "\n",
    "le = utils.crossover(le, 0.5)\n",
    "se = utils.crossover(se, 0.5)\n",
    "\n",
    "pf = vbt.Portfolio.from_signals(\n",
    "    df1['close'], open=df1['open'], high=df1['high'], low=df1['low'],\n",
    "    entries=le, #exits=lx,\n",
    "    short_entries=se, #short_exits=sx,\n",
    "    freq='1min',\n",
    "    td_stop=16,\n",
    "    time_delta_format=0,\n",
    "    sl_stop=0.02,\n",
    "    # tp_stop=0.04,\n",
    "    # tp_stop=5*df['natr'],\n",
    "    # slippage=0.0001,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.value.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pf.trades.records\n",
    "records['dt'] = df1.index[records['entry_idx']]\n",
    "records['exit_dt'] = df1.index[records['exit_idx']]\n",
    "records['sl'] = 0.02\n",
    "# records['sl'] = 3*df['natr'].iloc[records['entry_idx']].values\n",
    "records['realized_r'] = records['return']/records['sl']\n",
    "records = records.set_index('dt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['realized_r'].cumsum().plot()\n",
    "records[records['direction']==0]['realized_r'].cumsum().plot(label='long')\n",
    "records[records['direction']==1]['realized_r'].cumsum().plot(label='short')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['entry'] = np.where(le|se, df1['espf'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(make_subplots(rows=3, cols=1, shared_xaxes=True))\n",
    "fig.add_trace(go.Candlestick(), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(mode='markers'), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(mode='markers'), row=3, col=1)\n",
    "fig.add_trace(go.Scatter(), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(), row=2, col=1)\n",
    "fig.add_trace(go.Scatter(mode='markers'), row=2, col=1)\n",
    "fig.update_layout(height=600, margin=dict(l=20,r=20,b=20,t=20), xaxis=dict(rangeslider=dict(visible=False)))\n",
    "\n",
    "@interact(date=np.unique(df1['entry'].dropna().index.date), col=df1.columns, col2=df1.columns)\n",
    "def update(date, col, col2):\n",
    "   with fig.batch_update():\n",
    "      _sdf = df1.loc[str(date)]\n",
    "      fig.data[0].x, fig.data[0].open, fig.data[0].high = _sdf.index, _sdf['open'], _sdf['high']\n",
    "      fig.data[0].low, fig.data[0].close = _sdf['low'], _sdf['close']\n",
    "      fig.data[1].x, fig.data[1].y = _sdf.index, _sdf[col]\n",
    "      fig.data[2].x, fig.data[2].y = _sdf.index, _sdf[col2]\n",
    "      fig.data[3].x, fig.data[3].y = _sdf.index, _sdf['espf']\n",
    "      fig.data[4].x, fig.data[4].y = _sdf.index, rms_mult*_sdf['rms']\n",
    "      fig.data[5].x, fig.data[5].y = _sdf.index, -rms_mult*_sdf['rms']\n",
    "      fig.data[6].x, fig.data[6].y = _sdf.index, _sdf['entry']\n",
    "      fig.update_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.FigureWidget(make_subplots(rows=1, cols=1, shared_xaxes=True))\n",
    "fig.add_trace(go.Candlestick(), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(mode='markers', marker=dict(symbol='x', size=12, color='green')), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(mode='markers', marker=dict(symbol='x', size=12, color='red')), row=1, col=1)\n",
    "fig.update_layout(height=800, margin=dict(l=20,r=20,b=20,t=20), xaxis=dict(rangeslider=dict(visible=False)))\n",
    "\n",
    "@interact(r=records.index, col=df.columns, col2=df.columns)\n",
    "def update(r, col, col2):\n",
    "   with fig.batch_update():\n",
    "      _r = records.loc[r]\n",
    "      _sdf = df1.loc[str(_r.name.date())]\n",
    "      \n",
    "      print(_r['return'])\n",
    "      fig.data[0].x, fig.data[0].open, fig.data[0].high = _sdf.index, _sdf['open'], _sdf['high']\n",
    "      fig.data[0].low, fig.data[0].close = _sdf['low'], _sdf['close']\n",
    "    #   fig.data[1].x, fig.data[1].y = [_r.name, _r['exit_dt']], [_r['sl'],_r['sl']]\n",
    "    #   fig.data[2].x, fig.data[2].y = [_r.name, _r['exit_dt']], [_r['tp'],_r['tp']]\n",
    "      fig.data[3].x, fig.data[3].y = [_r.name], [_r['entry_price']]\n",
    "      fig.data[4].x, fig.data[4].y = [_r['exit_dt']], [_r['exit_price']]\n",
    "      fig.update_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_blog-4UPSDfUr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
